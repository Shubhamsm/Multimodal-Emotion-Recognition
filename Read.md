Text:
    
    Custom natural language preprocessing :
        Tokenization of the document
        Cleaning and standardization of formulations using regular expressions
        Deletion of the punctuation
        Lowercasing the tokens
        Removal of predefined stopwords
        Application of part-of-speech tags on the remaining tokens
        Lemmatization of tokens using part-of-speech tags for more accuracy.
        Padding the sequences of tokens of each document to constrain the shape of the input vectors.




=========================
Samples;
    Hello this is a beautiful day... We're making a Major project based on Sentimental Analysis
